{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "a583c4d1-ca4c-49ad-8bc6-76a3c189a83b",
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "05c02f61-19bb-456b-8ce8-3ff8a7dbdaa5",
   "metadata": {},
   "outputs": [],
   "source": [
    "housing = \"Housing.csv\"\n",
    "df = pd.read_csv(housing)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "7cfef867-4020-4a30-9c5c-0de3770e5c5e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def h(X, w):\n",
    "    return np.dot(X, w)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "91246a4a-b929-43d5-8f0d-019ff4275b68",
   "metadata": {},
   "outputs": [],
   "source": [
    "def loss_function(X, y, w):\n",
    "    m = X.shape[0]\n",
    "    return np.square(h(X, w) - y).sum() / (2 * m)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "147d2a21-dc5a-4f6d-a80f-192d6da26afe",
   "metadata": {},
   "outputs": [],
   "source": [
    "def grad_step(w, grad_w, learning_rate=0.001):\n",
    "    w = w - learning_rate*grad_w\n",
    "    return w"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "865fe2c5-333a-4ada-a9c7-ca76251dd065",
   "metadata": {},
   "outputs": [],
   "source": [
    "def grad_w(X, y, w):\n",
    "    m = X.shape[0]\n",
    "    return np.dot(X.T, (h(X, w) - y)) / m"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "797eb6e7-1ac3-44e8-8b6a-27c130d16be8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def grad_descent(w, X, y, num_iter=10000, learning_rate=0.001, epsilon=0.0000001):\n",
    "\n",
    "    loss = loss_function(X, y, w)\n",
    "    loss_history = [loss]\n",
    "\n",
    "    for i in range(num_iter):\n",
    "        w_best = None\n",
    "        d_w = grad_w(X, y, w)\n",
    "        w = grad_step(w, d_w, learning_rate=learning_rate)\n",
    "\n",
    "        loss = loss_function(X, y, w)\n",
    "        if abs(loss - loss_history[-1]) < epsilon:\n",
    "            loss_history.append(loss)\n",
    "            w_best = d_w\n",
    "            break\n",
    "        \n",
    "        loss_history.append(loss)\n",
    "        \n",
    "\n",
    "    return w, w_best, loss_history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "7a722b92-3a32-479a-a5c0-cf29e408bf58",
   "metadata": {},
   "outputs": [],
   "source": [
    "def normalization(data):\n",
    "    return (data - data.mean())/data.std()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "2c8091e7-a19e-4267-b9e2-c4e1a91af247",
   "metadata": {},
   "outputs": [],
   "source": [
    "norm_df = pd.DataFrame()\n",
    "\n",
    "norm_df[\"price\"] = normalization(df[\"price\"])\n",
    "norm_df[\"area\"] = normalization(df[\"area\"])\n",
    "norm_df[\"bathrooms\"] = normalization(df[\"bathrooms\"])\n",
    "norm_df[\"bedrooms\"] = normalization(df[\"bedrooms\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "ad83f320-b1f9-45f3-8cb8-867f1466ee65",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = norm_df[['area', 'bathrooms', 'bedrooms']].values\n",
    "X = np.hstack((np.ones((X.shape[0], 1)) , X))\n",
    "y = norm_df[\"price\"].values.reshape(-1, 1)\n",
    "\n",
    "n = X.shape[1]\n",
    "w = np.linspace(0, 0, n).reshape((n, 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "82e57deb-9543-4e32-98ed-b546d5129d75",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The best values w:  [ 6.19280366e-17 -6.74033514e-03 -4.72771123e-03  5.66844067e-03]\n",
      "The best values of loss function:  0.2560534283325343\n"
     ]
    }
   ],
   "source": [
    "w, w_best, loss_history = grad_descent(w, X, y, 10000, learning_rate=0.001)\n",
    "loss_best = loss_history[-1]\n",
    "print('Найкаще значення w: ', w_best.flatten())\n",
    "print('Найкраще значення функції втрат: ', loss_best)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "5494faf4-4eda-4d09-8bff-9c8e6a71baeb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The best analitical w:  [-1.26409176e-16  4.39452085e-01  3.72344423e-01  1.60528660e-01]\n",
      "The best analitical loss function:  0.25598790065321353\n"
     ]
    }
   ],
   "source": [
    "analitical_w = np.dot(np.dot(np.linalg.inv(np.dot(X.T, X)), X.T), y)\n",
    "analitical_loss = loss_function(X, y, analitical_w)\n",
    "print('Найкраще аналітичне значення w: ', analitical_w.flatten())\n",
    "print('Найкраще аналітичне значення функції втрат: ', analitical_loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "92cc43a3-3eaf-44b7-ba36-26a39446e722",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The best values of loss function:  0.2560534283325343\n",
      "The best analitical loss function:  0.25598790065321353\n"
     ]
    }
   ],
   "source": [
    "print('Найкраще значення функції втрат: ', loss_best)\n",
    "print('Найкраще аналітичне значення функції втрат: ', analitical_loss)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "anaconda-panel-2023.05-py310",
   "language": "python",
   "name": "conda-env-anaconda-panel-2023.05-py310-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
